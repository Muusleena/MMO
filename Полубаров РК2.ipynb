{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Полубаров РК2.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["Рубежный контроль No1 по курсу \"Методы машинного обучения\"\n","\n","Выполнил: Полубаров А.Н. Группа ИУ5-21М\n","\n","Вариант 10\n","\n","Задание:\n","\n","Необходимо решить задачу классификации текстов на основе любого выбранного Вами датасета (кроме примера, который рассматривался в лекции). Классификация может быть бинарной или многоклассовой. Целевой признак из выбранного Вами датасета может иметь любой физический смысл, примером является задача анализа тональности текста.\n","\n","Необходимо сформировать два варианта векторизации признаков - на основе CountVectorizer и на основе TfidfVectorizer.\n","\n","В качестве классификаторов необходимо использовать два классификатора по варианту для Вашей группы:\n","\n","LogisticRegression и Multinomial Naive Bayes (MNB)\n"],"metadata":{"id":"UN5c8H2053XC"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"raYIs_DONqCU","executionInfo":{"status":"ok","timestamp":1655020546135,"user_tz":-180,"elapsed":1228,"user":{"displayName":"Aleksandr Polubarov","userId":"08143123472653379257"}}},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","from typing import Dict, Tuple\n","from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n","from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n","from sklearn.metrics import accuracy_score, balanced_accuracy_score\n","from sklearn.metrics import precision_score, recall_score, f1_score, classification_report\n","from sklearn.metrics import confusion_matrix\n","from sklearn.model_selection import cross_val_score\n","from sklearn.pipeline import Pipeline\n","from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_squared_log_error, median_absolute_error, r2_score \n","from sklearn.metrics import roc_curve, roc_auc_score\n","from sklearn.naive_bayes import MultinomialNB\n","from sklearn.linear_model import LogisticRegression\n","import seaborn as sns\n","from collections import Counter\n","from sklearn.datasets import fetch_20newsgroups\n","import matplotlib.pyplot as plt\n","\n","%matplotlib inline \n","sns.set(style=\"ticks\")"]},{"cell_type":"code","source":["categories = [\"rec.motorcycles\", \"rec.sport.baseball\", \"sci.electronics\",\"sci.med\"]\n","newsgroups = fetch_20newsgroups(subset='train', categories=categories)\n","data = newsgroups['data']"],"metadata":{"id":"LAYLTiQ3PIQi","executionInfo":{"status":"ok","timestamp":1655020707371,"user_tz":-180,"elapsed":398,"user":{"displayName":"Aleksandr Polubarov","userId":"08143123472653379257"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["def accuracy_score_for_classes(\n","    y_true: np.ndarray, \n","    y_pred: np.ndarray) -> Dict[int, float]:\n","    \"\"\"\n","    Вычисление метрики accuracy для каждого класса\n","    y_true - истинные значения классов\n","    y_pred - предсказанные значения классов\n","    Возвращает словарь: ключ - метка класса, \n","    значение - Accuracy для данного класса\n","    \"\"\"\n","    # Для удобства фильтрации сформируем Pandas DataFrame \n","    d = {'t': y_true, 'p': y_pred}\n","    df = pd.DataFrame(data=d)\n","    # Метки классов\n","    classes = np.unique(y_true)\n","    # Результирующий словарь\n","    res = dict()\n","    # Перебор меток классов\n","    for c in classes:\n","        # отфильтруем данные, которые соответствуют \n","        # текущей метке класса в истинных значениях\n","        temp_data_flt = df[df['t']==c]\n","        # расчет accuracy для заданной метки класса\n","        temp_acc = accuracy_score(\n","            temp_data_flt['t'].values, \n","            temp_data_flt['p'].values)\n","        # сохранение результата в словарь\n","        res[c] = temp_acc\n","    return res\n","\n","def print_accuracy_score_for_classes(\n","    y_true: np.ndarray, \n","    y_pred: np.ndarray):\n","    \"\"\"\n","    Вывод метрики accuracy для каждого класса\n","    \"\"\"\n","    accs = accuracy_score_for_classes(y_true, y_pred)\n","    if len(accs)>0:\n","        print('Метка \\t Accuracy')\n","    for i in accs:\n","        print('{} \\t {}'.format(i, accs[i]))"],"metadata":{"id":"-4nIUfcVPSF3","executionInfo":{"status":"ok","timestamp":1655020557832,"user_tz":-180,"elapsed":9,"user":{"displayName":"Aleksandr Polubarov","userId":"08143123472653379257"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["vocabVect = CountVectorizer()\n","vocabVect.fit(data)\n","corpusVocab = vocabVect.vocabulary_\n","print('Количество сформированных признаков - {}'.format(len(corpusVocab)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_SBr_LIdPZlC","outputId":"ee2bf848-fabe-43d9-8b3f-43f1a45ac828","executionInfo":{"status":"ok","timestamp":1655020558865,"user_tz":-180,"elapsed":1041,"user":{"displayName":"Aleksandr Polubarov","userId":"08143123472653379257"}}},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Количество сформированных признаков - 33448\n"]}]},{"cell_type":"code","source":["for i in list(corpusVocab)[1:10]:\n","    print('{}={}'.format(i, corpusVocab[i]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CDAOrqSSPbjp","outputId":"bbe6c798-0c22-4d35-b447-9ae994777e2a","executionInfo":{"status":"ok","timestamp":1655020558866,"user_tz":-180,"elapsed":4,"user":{"displayName":"Aleksandr Polubarov","userId":"08143123472653379257"}}},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["nrmendel=22213\n","unix=31462\n","amherst=5287\n","edu=12444\n","nathaniel=21624\n","mendell=20477\n","subject=29220\n","re=25369\n","bike=6898\n"]}]},{"cell_type":"code","source":["test_features = vocabVect.transform(data)\n","test_features"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dkLIFJl4PdSY","outputId":"0aeb897e-f7cc-4a1d-ca90-7bffb367237e","executionInfo":{"status":"ok","timestamp":1655020559350,"user_tz":-180,"elapsed":486,"user":{"displayName":"Aleksandr Polubarov","userId":"08143123472653379257"}}},"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<2380x33448 sparse matrix of type '<class 'numpy.int64'>'\n","\twith 335176 stored elements in Compressed Sparse Row format>"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["# Размер нулевой строки\n","len(test_features.todense()[0].getA1())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KQ0O-qRdPe44","outputId":"5ee59ffb-a204-4385-b05c-6d99e4b48cd9","executionInfo":{"status":"ok","timestamp":1655020559718,"user_tz":-180,"elapsed":369,"user":{"displayName":"Aleksandr Polubarov","userId":"08143123472653379257"}}},"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["33448"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["vocabVect.get_feature_names()[100:120]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JZC8r5YZPgvI","outputId":"ac2f5cb9-6497-443b-98d0-183ac0f06fda","executionInfo":{"status":"ok","timestamp":1655020560074,"user_tz":-180,"elapsed":360,"user":{"displayName":"Aleksandr Polubarov","userId":"08143123472653379257"}}},"execution_count":8,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n","  warnings.warn(msg, category=FutureWarning)\n"]},{"output_type":"execute_result","data":{"text/plain":["['01810',\n"," '01830',\n"," '018801285',\n"," '019',\n"," '02',\n"," '020',\n"," '0200',\n"," '020347',\n"," '0205',\n"," '020533',\n"," '020555',\n"," '020646',\n"," '02086551',\n"," '02115',\n"," '02118',\n"," '02138',\n"," '02139',\n"," '02142',\n"," '02154',\n"," '0216']"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["def VectorizeAndClassify(vectorizers_list, classifiers_list):\n","    for v in vectorizers_list:\n","        for c in classifiers_list:\n","            pipeline1 = Pipeline([(\"vectorizer\", v), (\"classifier\", c)])\n","            score = cross_val_score(pipeline1, newsgroups['data'], newsgroups['target'], scoring='accuracy', cv=3).mean()\n","            print('Векторизация - {}'.format(v))\n","            print('Модель для классификации - {}'.format(c))\n","            print('Accuracy = {}'.format(score))\n","            print('===========================')"],"metadata":{"id":"7LGyCYm9PjjD","executionInfo":{"status":"ok","timestamp":1655020560075,"user_tz":-180,"elapsed":3,"user":{"displayName":"Aleksandr Polubarov","userId":"08143123472653379257"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["vectorizers_list = [CountVectorizer(vocabulary = corpusVocab), TfidfVectorizer(vocabulary = corpusVocab)]\n","classifiers_list = [LogisticRegression(), MultinomialNB()]\n","VectorizeAndClassify(vectorizers_list, classifiers_list)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4HrHgzpjPmQv","outputId":"2955508c-cc84-4a17-b8a5-5a5f6b7e452f","executionInfo":{"status":"ok","timestamp":1655020601837,"user_tz":-180,"elapsed":41764,"user":{"displayName":"Aleksandr Polubarov","userId":"08143123472653379257"}}},"execution_count":10,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"]},{"output_type":"stream","name":"stdout","text":["Векторизация - CountVectorizer(vocabulary={'00': 0, '000': 1, '0000': 2, '0000000004': 3,\n","                            '0000000005': 4, '0000000667': 5, '0000001200': 6,\n","                            '0001': 7, '00014': 8, '0002': 9, '0003': 10,\n","                            '0005111312': 11, '0005111312na1em': 12,\n","                            '00072': 13, '000851': 14, '000rpm': 15,\n","                            '000th': 16, '001': 17, '0010': 18, '001004': 19,\n","                            '0011': 20, '001211': 21, '0013': 22, '001642': 23,\n","                            '001813': 24, '002': 25, '002222': 26,\n","                            '002251w': 27, '0023': 28, '002937': 29, ...})\n","Модель для классификации - LogisticRegression()\n","Accuracy = 0.9382336841146768\n","===========================\n","Векторизация - CountVectorizer(vocabulary={'00': 0, '000': 1, '0000': 2, '0000000004': 3,\n","                            '0000000005': 4, '0000000667': 5, '0000001200': 6,\n","                            '0001': 7, '00014': 8, '0002': 9, '0003': 10,\n","                            '0005111312': 11, '0005111312na1em': 12,\n","                            '00072': 13, '000851': 14, '000rpm': 15,\n","                            '000th': 16, '001': 17, '0010': 18, '001004': 19,\n","                            '0011': 20, '001211': 21, '0013': 22, '001642': 23,\n","                            '001813': 24, '002': 25, '002222': 26,\n","                            '002251w': 27, '0023': 28, '002937': 29, ...})\n","Модель для классификации - MultinomialNB()\n","Accuracy = 0.9747904364702481\n","===========================\n","Векторизация - TfidfVectorizer(vocabulary={'00': 0, '000': 1, '0000': 2, '0000000004': 3,\n","                            '0000000005': 4, '0000000667': 5, '0000001200': 6,\n","                            '0001': 7, '00014': 8, '0002': 9, '0003': 10,\n","                            '0005111312': 11, '0005111312na1em': 12,\n","                            '00072': 13, '000851': 14, '000rpm': 15,\n","                            '000th': 16, '001': 17, '0010': 18, '001004': 19,\n","                            '0011': 20, '001211': 21, '0013': 22, '001642': 23,\n","                            '001813': 24, '002': 25, '002222': 26,\n","                            '002251w': 27, '0023': 28, '002937': 29, ...})\n","Модель для классификации - LogisticRegression()\n","Accuracy = 0.9584091700786584\n","===========================\n","Векторизация - TfidfVectorizer(vocabulary={'00': 0, '000': 1, '0000': 2, '0000000004': 3,\n","                            '0000000005': 4, '0000000667': 5, '0000001200': 6,\n","                            '0001': 7, '00014': 8, '0002': 9, '0003': 10,\n","                            '0005111312': 11, '0005111312na1em': 12,\n","                            '00072': 13, '000851': 14, '000rpm': 15,\n","                            '000th': 16, '001': 17, '0010': 18, '001004': 19,\n","                            '0011': 20, '001211': 21, '0013': 22, '001642': 23,\n","                            '001813': 24, '002': 25, '002222': 26,\n","                            '002251w': 27, '0023': 28, '002937': 29, ...})\n","Модель для классификации - MultinomialNB()\n","Accuracy = 0.9722710153812272\n","===========================\n"]}]},{"cell_type":"markdown","source":["Как видно из результатов, лучшую точность показал CountVectorizer и MultinomialNB (Точность составила 97,48%)"],"metadata":{"id":"ElVgR0hhP1uW"}}]}